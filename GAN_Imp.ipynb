{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "hidden_dim = 256\n",
    "image_dim = 784\n",
    "batch_size = 64\n",
    "num_epochs = 100  # Increased epochs\n",
    "lr = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, image_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and save sample images\n",
    "def save_samples(generator, fixed_noise, epoch, fig_size=(10, 10)):\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(fixed_noise)\n",
    "        fake_images = fake_images.view(-1, 28, 28)\n",
    "        \n",
    "        plt.figure(figsize=fig_size)\n",
    "        for i in range(16):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            plt.imshow(fake_images[i].cpu().numpy(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.suptitle(f'Generated Images at Epoch {epoch}', fontsize=20)\n",
    "        plt.tight_layout()\n",
    "        return plt.gcf()\n",
    "\n",
    "# Load MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                 transform=transform, download=True)\n",
    "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize networks and optimizers\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Fixed noise for visualization\n",
    "fixed_noise = torch.randn(16, latent_dim,device=device)\n",
    "\n",
    "# Training loop with visualization\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "evolution_images = []\n",
    "checkpoints = [1, 10, 25, 50, 75, 100]  # Epochs to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize():\n",
    "    for epoch in range(num_epochs):\n",
    "        d_loss_epoch = 0\n",
    "        g_loss_epoch = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx, (real_images, _) in enumerate(dataloader):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.view(batch_size, -1).to(device)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            discriminator.zero_grad()\n",
    "            real_labels = torch.ones(batch_size, 1,device=device)\n",
    "            fake_labels = torch.zeros(batch_size, 1,device=device)\n",
    "            \n",
    "            outputs = discriminator(real_images)\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            \n",
    "            z = torch.randn(batch_size, latent_dim,device=device)\n",
    "            fake_images = generator(z)\n",
    "            outputs = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            generator.zero_grad()\n",
    "            outputs = discriminator(fake_images)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            d_loss_epoch += d_loss.item()\n",
    "            g_loss_epoch += g_loss.item()\n",
    "            batch_count += 1\n",
    "        \n",
    "        # Record losses\n",
    "        d_losses.append(d_loss_epoch / batch_count)\n",
    "        g_losses.append(g_loss_epoch / batch_count)\n",
    "        \n",
    "        # Save images at checkpoints\n",
    "        if (epoch + 1) in checkpoints:\n",
    "            evolution_images.append(save_samples(generator, fixed_noise, epoch + 1))\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_losses[-1]:.4f}, g_loss: {g_losses[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_and_visualize()\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(d_losses, label='Discriminator Loss')\n",
    "plt.plot(g_losses, label='Generator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display evolution grid\n",
    "plt.figure(figsize=(20, 12))\n",
    "for i, img in enumerate(evolution_images):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(img.canvas.renderer.buffer_rgba())\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Evolution of Generated Images During Training', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".MYENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
